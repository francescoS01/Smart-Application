{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY0IUGtZawl3"
      },
      "source": [
        "# RAG graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVHjElalVdIv",
        "outputId": "85103490-e064-439c-cd2b-b246cbb74695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_community in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (0.3.5)\n",
            "Requirement already satisfied: tiktoken in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (0.8.0)\n",
            "Requirement already satisfied: langchain-openai in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (0.2.9)\n",
            "Requirement already satisfied: langchainhub in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (0.1.21)\n",
            "Requirement already satisfied: chromadb in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (0.5.20)\n",
            "Requirement already satisfied: langchain in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (0.3.7)\n",
            "Requirement already satisfied: transformers in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (4.46.1)\n",
            "Requirement already satisfied: faiss-cpu in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (1.9.0)\n",
            "Requirement already satisfied: networkx in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (3.2.1)\n",
            "Requirement already satisfied: huggingface-hub in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (0.26.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (0.3.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (0.1.139)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain-openai) (1.55.0)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchainhub) (24.1)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchainhub) (2.32.0.20241016)\n",
            "Requirement already satisfied: build>=1.0.3 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (2.9.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (0.115.5)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (3.7.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (1.19.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (0.20.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (1.68.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (0.13.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: filelock in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from huggingface-hub) (2024.10.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.1)\n",
            "Requirement already satisfied: pyproject_hooks in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.6 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (8.5.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (2.0.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
            "Requirement already satisfied: anyio in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (4.6.2.post1)\n",
            "Requirement already satisfied: certifi in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
            "Requirement already satisfied: idna in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.36.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (5.28.3)\n",
            "Requirement already satisfied: sympy in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.7.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-proto==1.28.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.49b2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from importlib-resources->chromadb) (3.20.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/chiarapiccolo/miniconda3/envs/SA_env/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain transformers faiss-cpu networkx huggingface-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hWvpD2Czawl-"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFacePipeline, GPT4All, HuggingFaceHub\n",
        "from langchain.chains import LLMChain, RetrievalQA\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "import re\n",
        "import networkx as nx\n",
        "import torch\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx7arZ1cdF_r"
      },
      "source": [
        "## Retrieval Part (to be changed with the new one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XYisOLEawl-"
      },
      "source": [
        "### Knowledge Base (KB) Graph Structure\n",
        "\n",
        "- **Nodes**:\n",
        "  - **Machine Nodes**: Represent machines with attributes like `model` and `manufacturer`.\n",
        "  - **Base KPI Nodes**: Directly measured and stored in the database, such as:\n",
        "    - `WorkingTime`: Measures time actively working.\n",
        "    - `IdleTime`: Measures time idle but available.\n",
        "    - `OfflineTime`: Measures time offline and unavailable.\n",
        "  - **Non-Base KPI Nodes**: KPIs that require calculation based on Base KPIs, including:\n",
        "    - `TotalAvailableTime`: Sum of `WorkingTime` and `IdleTime`.\n",
        "    - `UtilizationRate`: Percentage of active working time as a function of availability.\n",
        "\n",
        "- **Edges**:\n",
        "  - **Machine-KPI Relationships**:\n",
        "    - Each machine node is linked to Base KPI nodes with a `\"measures\"` edge.\n",
        "  - **KPI Dependencies**:\n",
        "    - Non-Base KPIs are connected to their required Base KPIs with `\"depends_on\"` edges, allowing dynamic calculation.\n",
        "\n",
        "This organization helps the RAG agent understand:\n",
        "- **Direct measurements**: From machine to Base KPIs.\n",
        "- **Dependency hierarchy**: For calculated KPIs using other KPIs as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qUzfq45Mawl-"
      },
      "outputs": [],
      "source": [
        "# Initialize a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add Machine Nodes with Attributes\n",
        "G.add_node(\"LaserCutter_1\", node_type=\"Machine\", model=\"LC-200\", manufacturer=\"Brand A\")\n",
        "G.add_node(\"LaserCutter_2\", node_type=\"Machine\", model=\"LC-300\", manufacturer=\"Brand B\")\n",
        "\n",
        "# Add KPI Nodes with Descriptions and Normal Ranges\n",
        "# Base KPIs (no fromula, directly saved in the DB)\n",
        "G.add_node(\n",
        "    \"WorkingTime\",\n",
        "    node_type=\"Base KPI\",\n",
        "    description=\"Time actively working\",\n",
        "    unit=\"seconds\",\n",
        "    normal_min=6,\n",
        "    normal_max=10)\n",
        "\n",
        "G.add_node(\"IdleTime\",\n",
        "           node_type=\"Base KPI\",\n",
        "           description=\"Time idle but available\",\n",
        "           unit=\"seconds\",\n",
        "           normal_min=1,\n",
        "           normal_max=4)\n",
        "\n",
        "G.add_node(\"OfflineTime\",\n",
        "           node_type=\"Base KPI\",\n",
        "           description=\"Time offline and not available\",\n",
        "           unit=\"seconds\",\n",
        "           normal_min=0,\n",
        "           normal_max=2)\n",
        "\n",
        "\n",
        "# New KPIs (calculation needed)\n",
        "# Define new KPI nodes\n",
        "G.add_node(\n",
        "    \"TotalAvailableTime\",\n",
        "    node_type=\"NB_KPI\",\n",
        "    description=\"Total time available for work (including working and idle time)\",\n",
        "    unit=\"seconds\",\n",
        "    normal_min=7,\n",
        "    normal_max=14,\n",
        "    formula=\"WorkingTime + IdleTime\"\n",
        ")\n",
        "\n",
        "G.add_node(\n",
        "    \"UtilizationRate\",\n",
        "    node_type=\"NB_KPI\",\n",
        "    description=\"Percentage of time actively working while available\",\n",
        "    unit=\"percentage\",\n",
        "    normal_min=60,\n",
        "    normal_max=90,\n",
        "    formula=\"(WorkingTime / (WorkingTime + IdleTime)) * 100\"\n",
        ")\n",
        "\n",
        "# Add Directed Relationships (Edges) Between Machines and KPIs\n",
        "G.add_edge(\"LaserCutter_1\", \"WorkingTime\", relationship=\"measures\")\n",
        "G.add_edge(\"LaserCutter_1\", \"IdleTime\", relationship=\"measures\")\n",
        "G.add_edge(\"LaserCutter_1\", \"OfflineTime\", relationship=\"measures\")\n",
        "\n",
        "G.add_edge(\"LaserCutter_2\", \"WorkingTime\", relationship=\"measures\")\n",
        "G.add_edge(\"LaserCutter_2\", \"IdleTime\", relationship=\"measures\")\n",
        "G.add_edge(\"LaserCutter_2\", \"OfflineTime\", relationship=\"measures\")\n",
        "\n",
        "G.add_edge(\"LaserCutter_1\", \"TotalAvailableTime\", relationship =\"measures\")\n",
        "G.add_edge(\"LaserCutter_1\", \"UtilizationRate\", relationship =\"measures\")\n",
        "G.add_edge(\"LaserCutter_2\", \"TotalAvailableTime\", relationship =\"measures\")\n",
        "G.add_edge(\"LaserCutter_2\", \"UtilizationRate\", relationship =\"measures\")\n",
        "\n",
        "\n",
        "# Add Directed Relationships (Edges) Between KPIs (base and calculated ones)\n",
        "G.add_edge(\"TotalAvailableTime\", \"WorkingTime\", relationship=\"depends_on\")\n",
        "G.add_edge(\"TotalAvailableTime\", \"IdleTime\", relationship=\"depends_on\")\n",
        "\n",
        "G.add_edge(\"UtilizationRate\", \"WorkingTime\", relationship=\"depends_on\")\n",
        "G.add_edge(\"UtilizationRate\", \"IdleTime\", relationship=\"depends_on\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz0f2cZSawl_"
      },
      "source": [
        "### Create embeddings for each node\n",
        "\n",
        "For each node, a textual description is created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byFVJP8Sawl_",
        "outputId": "e5ae6c63-53ec-46fd-eaba-49e618ebc444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LaserCutter_1: it is a Machine. Model LC-200, manufactured by Brand A. It has the following KPIs: WorkingTime, IdleTime, OfflineTime, TotalAvailableTime, UtilizationRate.\n",
            "LaserCutter_2: it is a Machine. Model LC-300, manufactured by Brand B. It has the following KPIs: WorkingTime, IdleTime, OfflineTime, TotalAvailableTime, UtilizationRate.\n",
            "WorkingTime: it is a base KPI. It measures Time actively working in seconds. Reference range is 6 to 10. Used by machines: LaserCutter_1, LaserCutter_2.\n",
            "IdleTime: it is a base KPI. It measures Time idle but available in seconds. Reference range is 1 to 4. Used by machines: LaserCutter_1, LaserCutter_2.\n",
            "OfflineTime: it is a base KPI. It measures Time offline and not available in seconds. Reference range is 0 to 2. Used by machines: LaserCutter_1, LaserCutter_2.\n",
            "TotalAvailableTime: it is a non-base KPI. It measures Total time available for work (including working and idle time) in seconds. Reference range is 7 to 14. Calculated from: WorkingTime, IdleTime. Formula: WorkingTime + IdleTime.\n",
            "UtilizationRate: it is a non-base KPI. It measures Percentage of time actively working while available in percentage. Reference range is 60 to 90. Calculated from: WorkingTime, IdleTime. Formula: (WorkingTime / (WorkingTime + IdleTime)) * 100.\n"
          ]
        }
      ],
      "source": [
        "# Function to generate descriptions automatically\n",
        "def generate_descriptions(graph):\n",
        "    descriptions = {}\n",
        "\n",
        "    for node in graph.nodes(data=True):\n",
        "        node_name, attributes = node\n",
        "        node_type = attributes.get(\"node_type\")\n",
        "\n",
        "        if node_type == \"Machine\":\n",
        "            # Find KPIs measured by this machine\n",
        "            kpis = [\n",
        "                target for source, target, data in graph.edges(data=True)\n",
        "                if source == node_name and data[\"relationship\"] == \"measures\"\n",
        "            ]\n",
        "            kpi_list = \", \".join(kpis)\n",
        "\n",
        "            # Generate description using template for machines\n",
        "            descriptions[node_name] = (\n",
        "                f\"it is a Machine. Model {attributes.get('model')}, \"\n",
        "                f\"manufactured by {attributes.get('manufacturer')}. It has the following KPIs: {kpi_list}.\"\n",
        "            )\n",
        "\n",
        "        elif node_type == \"Base KPI\":\n",
        "            # Find machines that measure this Base KPI\n",
        "            machines = [\n",
        "                source for source, target, data in graph.edges(data=True)\n",
        "                if target == node_name and data[\"relationship\"] == \"measures\"\n",
        "            ]\n",
        "            machine_list = \", \".join(machines)\n",
        "\n",
        "            # Generate description using template for Base KPIs\n",
        "            descriptions[node_name] = (\n",
        "                f\"it is a base KPI. It measures {attributes.get('description')} in {attributes.get('unit')}. \"\n",
        "                f\"Reference range is {attributes.get('normal_min')} to {attributes.get('normal_max')}. \"\n",
        "                f\"Used by machines: {machine_list}.\"\n",
        "            )\n",
        "\n",
        "        elif node_type == \"NB_KPI\":\n",
        "            # Find dependencies for this Non-Base KPI\n",
        "            dependencies = [\n",
        "                target for source, target, data in graph.edges(data=True)\n",
        "                if source == node_name and data[\"relationship\"] == \"depends_on\"\n",
        "            ]\n",
        "            dependency_list = \", \".join(dependencies)\n",
        "\n",
        "            # Generate description using template for Non-Base KPIs\n",
        "            descriptions[node_name] = (\n",
        "                f\"it is a non-base KPI. It measures {attributes.get('description')} in {attributes.get('unit')}. \"\n",
        "                f\"Reference range is {attributes.get('normal_min')} to {attributes.get('normal_max')}. \"\n",
        "                f\"Calculated from: {dependency_list}. Formula: {attributes.get('formula')}.\"\n",
        "            )\n",
        "\n",
        "    return descriptions\n",
        "\n",
        "# Generate and print descriptions for all nodes\n",
        "generated_descriptions = generate_descriptions(G)\n",
        "descriptions = []\n",
        "\n",
        "\n",
        "for node, desc in generated_descriptions.items():\n",
        "    print(f\"{node}: {desc}\")\n",
        "    descriptions.append({node: desc})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wHwAkq3i1rw3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/sp/6tltq_zj57n0ys2h5jz2ch3h0000gn/T/ipykernel_60396/2713839655.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Convert node descriptions into Langchain Document objects\n",
        "documents = []\n",
        "\n",
        "# Iterate over the list of dictionaries in `descriptions`\n",
        "for item in descriptions:\n",
        "    for node, desc in item.items():  # Extract the key-value pair from each dictionary\n",
        "        # Include the node name in the page content to make it explicit\n",
        "        document_text = f\"{node}: {desc}\"\n",
        "        documents.append(Document(page_content=document_text, metadata={\"node\": node}))\n",
        "\n",
        "# Step 2: Generate embeddings for each node description using HuggingFace\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "embeddings = [embedding_model.embed_query(doc.page_content) for doc in documents]\n",
        "\n",
        "# Step 3: Create FAISS index and add the embeddings\n",
        "dimension = len(embeddings[0])\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "faiss_index.add(np.array(embeddings))\n",
        "\n",
        "# Step 4: Create `index_to_docstore_id` and a `docstore`\n",
        "index_to_docstore_id = {i: str(i) for i in range(len(documents))}\n",
        "docstore = InMemoryDocstore(({str(i): doc for i, doc in enumerate(documents)}))\n",
        "\n",
        "# Step 5: Create FAISS vector store with HuggingFace embeddings and the node documents\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embedding_model,\n",
        "    index=faiss_index,\n",
        "    docstore=docstore,\n",
        "    index_to_docstore_id=index_to_docstore_id\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYi4GfyiVZq4",
        "outputId": "448cda00-3ae7-4a42-ed96-50fe95b2eb97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LaserCutter_1: it is a Machine. Model LC-200, manufactured by Brand A. It has the following KPIs: WorkingTime, IdleTime, OfflineTime, TotalAvailableTime, UtilizationRate. {'node': 'LaserCutter_1'}\n",
            "LaserCutter_2: it is a Machine. Model LC-300, manufactured by Brand B. It has the following KPIs: WorkingTime, IdleTime, OfflineTime, TotalAvailableTime, UtilizationRate. {'node': 'LaserCutter_2'}\n",
            "WorkingTime: it is a base KPI. It measures Time actively working in seconds. Reference range is 6 to 10. Used by machines: LaserCutter_1, LaserCutter_2. {'node': 'WorkingTime'}\n",
            "IdleTime: it is a base KPI. It measures Time idle but available in seconds. Reference range is 1 to 4. Used by machines: LaserCutter_1, LaserCutter_2. {'node': 'IdleTime'}\n",
            "OfflineTime: it is a base KPI. It measures Time offline and not available in seconds. Reference range is 0 to 2. Used by machines: LaserCutter_1, LaserCutter_2. {'node': 'OfflineTime'}\n",
            "TotalAvailableTime: it is a non-base KPI. It measures Total time available for work (including working and idle time) in seconds. Reference range is 7 to 14. Calculated from: WorkingTime, IdleTime. Formula: WorkingTime + IdleTime. {'node': 'TotalAvailableTime'}\n",
            "UtilizationRate: it is a non-base KPI. It measures Percentage of time actively working while available in percentage. Reference range is 60 to 90. Calculated from: WorkingTime, IdleTime. Formula: (WorkingTime / (WorkingTime + IdleTime)) * 100. {'node': 'UtilizationRate'}\n",
            "(384,)\n",
            "Embedding 0: Length = 384\n",
            "(384,)\n",
            "Embedding 1: Length = 384\n",
            "(384,)\n",
            "Embedding 2: Length = 384\n",
            "(384,)\n",
            "Embedding 3: Length = 384\n",
            "(384,)\n",
            "Embedding 4: Length = 384\n",
            "(384,)\n",
            "Embedding 5: Length = 384\n",
            "(384,)\n",
            "Embedding 6: Length = 384\n",
            "FAISS index size: 7\n"
          ]
        }
      ],
      "source": [
        "# Verification: Print documents to verify the KPI names are included in the content\n",
        "for doc in documents:\n",
        "    print(doc.page_content, doc.metadata)\n",
        "\n",
        "# Verification: Print embedding lengths\n",
        "for i, embedding in enumerate(embeddings):\n",
        "\n",
        "  embedding = np.array(embedding)\n",
        "  print(embedding.shape)\n",
        "  print(f\"Embedding {i}: Length = {len(embedding)}\")\n",
        "\n",
        "# Verification: Print FAISS index size\n",
        "print(f\"FAISS index size: {faiss_index.ntotal}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nncLVh505szI",
        "outputId": "e68a5be0-641b-457a-8548-d79c6f52f69b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved:\n",
            " LaserCutter_2: it is a Machine. Model LC-300, manufactured by Brand B. It has the following KPIs: WorkingTime, IdleTime, OfflineTime, TotalAvailableTime, UtilizationRate.\n",
            "Retrieved:\n",
            " LaserCutter_1: it is a Machine. Model LC-200, manufactured by Brand A. It has the following KPIs: WorkingTime, IdleTime, OfflineTime, TotalAvailableTime, UtilizationRate.\n",
            "Retrieved:\n",
            " WorkingTime: it is a base KPI. It measures Time actively working in seconds. Reference range is 6 to 10. Used by machines: LaserCutter_1, LaserCutter_2.\n",
            "Retrieved:\n",
            " OfflineTime: it is a base KPI. It measures Time offline and not available in seconds. Reference range is 0 to 2. Used by machines: LaserCutter_1, LaserCutter_2.\n"
          ]
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever()\n",
        "test_query = \"Get info about Laser Cutter Machines\"\n",
        "results = retriever.invoke(test_query)\n",
        "for result in results:\n",
        "    print(f\"Retrieved:\\n {result.page_content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            " A Key Performance Indicator (KPI) is a measurable value that demonstrates how effectively a company or department is achieving key business objectives. KPIs are used to evaluate success at both the macro and micro levels, providing organizations with a way to track progress towards strategic goals and identify areas for improvement. They can be quantitative or qualitative, and are often expressed as ratios, percentages, or raw numbers. Examples of KPIs include revenue growth rate, customer satisfaction score, employee turnover rate, and website traffic.\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())  # Should return True if GPU is available\n",
        "\n",
        "\n",
        "model = ChatOpenAI(\n",
        "    base_url = 'http://localhost:11434/v1',\n",
        "    temperature = 0, #quanto il modello si deve attenere al prompt\n",
        "    api_key = 'not-needed',\n",
        "    model_name = 'mistral'\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"Tell me what a {argument} is.\")\n",
        "output_parser = StrOutputParser()\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "answer = chain.invoke({\"argument\" : \"KPI\"})\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generative Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Steps of elaboration of the user query:\n",
        "\n",
        "Check if the query can be answered (informational query) or if there is the need to retrieve historical data (action query):\n",
        "- if the query is informational, the model just answers it based on the provided context\n",
        "- if the query is action, the model has to extract specific elements to be able to contact the KPI calculation engine.\n",
        "\n",
        "The elements needed are:\n",
        "- kpi name\n",
        "- machine name\n",
        "- the query dateframe (single date, range of dates, aggregation period)\n",
        "- operation (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Define the different prompt temmplates\n",
        "enough_info_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    You are an evaluator.  Your job is not to answer the query. Your job is to decide whether historical data is needed to answer the query. \n",
        "    Explain your reasoning and conclude with a final answer: respond 'yes' if historical data is needed, otherwise 'no'. \n",
        "    You must strictly adhere to this format. \n",
        "    Context: {context}. Question: {query}. \n",
        "    Answer:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "informational_query_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Please answer the following question using the information in the provided context. \n",
        "    Your answer should be direct and concise, focusing specifically on addressing the question. \n",
        "    If the question asks for additional details, provide only the specific information requested. \n",
        "    Do not introduce information or explanations beyond what is directly asked for in the question. \n",
        "    Context: {context}. Question: {query}. \n",
        "    Answer:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "action_query_prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"\n",
        "    Analyze the provided query to extract specific details. Follow these steps precisely:\n",
        "\n",
        "    Step 1: Determine the Timeframe \n",
        "    Identify the timeframe mentioned in the query. Classify it into one of the following categories:\n",
        "\n",
        "    1. Specific Date:\n",
        "    - A single, specific point in time. Examples include:\n",
        "        - \"on September 15th\"\n",
        "        - \"on 2023-09-15\"\n",
        "        - \"yesterday\"\n",
        "        - \"two days ago\"\n",
        "    \n",
        "    2. Range of Dates:\n",
        "    - A continuous range that has a clear start and end date. Examples include:\n",
        "        - \"between September 1st and September 15th\"\n",
        "        - \"over the past week\"\n",
        "        - \"from July to August\"\n",
        "    - Note: A range always involves a start and an end date, covering all the days in between.\n",
        "\n",
        "    3. Aggregation Period:\n",
        "    - A period that indicates a repeating aggregation, usually associated with a specific frequency or regular interval, to group data. Examples include:\n",
        "        - \"monthly between July and September\" (meaning data grouped month by month)\n",
        "        - \"weekly in the last month\" (meaning data grouped week by week over the past month)\n",
        "    - Note: An aggregation period focuses on dividing the timeframe into repeated intervals (e.g., weekly, monthly) for aggregated analysis. Only classify it as an aggregation period if **explicit** mention of terms like \"monthly\", \"weekly\", or similar are found in the query.\n",
        "\n",
        "    Step 2: Identify the Operation\n",
        "    Check if the query mentions any of the following operations:\n",
        "    - sum, avg, max, min.\n",
        "    If no operation is mentioned, leave this field as 'null'.\n",
        "\n",
        "    Step 3: Extract the Following Details:\n",
        "    Extract and organize the information as described below:\n",
        "    - For a Specific Date:\n",
        "        - Provide it in the `start_range` field in YYYY-MM-DD format.\n",
        "    - For a Date Range:\n",
        "        - Provide both `start_range` and `end_range` fields in YYYY-MM-DD format.\n",
        "    - For an Aggregation Period:\n",
        "        - Provide `start_range` and `end_range` fields in YYYY-MM-DD format.\n",
        "        - Additionally, include the `aggregation` field (e.g., 'monthly', 'weekly', or 'daily').\n",
        "    - 'operation': Specify the operation mentioned (e.g., 'sum,' 'avg,' 'max,' 'min'). If none, set this field to 'null'.\n",
        "    - 'KPI_name': Identify the key performance indicator mentioned. \n",
        "    - 'machine_name': Determine the machine referred to in the query.\n",
        "\n",
        "    Return the extracted information in a structured format (json).\n",
        "    Today's date is {current_date} for reference.\n",
        "\n",
        "    Query: {query}.\n",
        "    Context: {context}.\n",
        "    Answer\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# Define the different pipelines\n",
        "chain1 = (\n",
        "    {\n",
        "        'context': RunnablePassthrough(), \n",
        "        'query': RunnablePassthrough()  \n",
        "    }\n",
        "    | enough_info_prompt  \n",
        "    | model  \n",
        "    | StrOutputParser()  \n",
        ")\n",
        "\n",
        "chain2 = (\n",
        "    {\n",
        "        'context': RunnablePassthrough(),  \n",
        "        'query': RunnablePassthrough()  \n",
        "    }\n",
        "    | informational_query_prompt \n",
        "    | model   \n",
        "    | StrOutputParser()  \n",
        ")\n",
        "\n",
        "chain3 = (\n",
        "    {\n",
        "        'context': RunnablePassthrough(), \n",
        "        'query': RunnablePassthrough(), \n",
        "        'current_date':  RunnablePassthrough()\n",
        "    }\n",
        "    | action_query_prompt \n",
        "    | model   \n",
        "    | StrOutputParser()  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_json_from_llm_response(response):\n",
        "    # Trova tutte le parti tra parentesi graffe\n",
        "    matches = re.findall(r'\\{.*?\\}', response, re.DOTALL)\n",
        "    \n",
        "    if not matches:\n",
        "        return {}\n",
        "    \n",
        "    # Considera solo il primo match, assumendo che sia il contenuto da convertire in JSON\n",
        "    content = matches[0]\n",
        "    \n",
        "    # Rimuove i commenti dopo le virgole\n",
        "    lines = content.splitlines()\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "        # Rimuove tutto dopo la virgola, se presente\n",
        "        cleaned_line = re.sub(r',.*', '', line).strip()\n",
        "        if cleaned_line:\n",
        "            cleaned_lines.append(cleaned_line)\n",
        "    \n",
        "    # Crea un dizionario filtrando solo gli elementi desiderati\n",
        "    desired_keys = [\"KPI_name\", \"machine_name\", \"start_range\", \"end_range\", \"aggregation\", \"operation\"]\n",
        "    result = {key: None for key in desired_keys}\n",
        "    \n",
        "    for line in cleaned_lines:\n",
        "        for key in desired_keys:\n",
        "            if line.startswith(f'\"{key}\"'):\n",
        "                # Estrae il valore dopo i due punti\n",
        "                value = line.split(':', 1)[-1].strip().strip('\"')\n",
        "                result[key] = value\n",
        "                break\n",
        "    \n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to call the RAG pipeline\n",
        "def steps(query, context, date):\n",
        "    # Step 1: initial prompt (chian1)\n",
        "    input_data = {\"context\": context, \"query\": query}\n",
        "    response_1 = chain1.invoke(input_data)\n",
        "    #print(\"\\nResponse: {}\".format(response_1))\n",
        "\n",
        "    # Step 2: Check the first two tokens \n",
        "    first_two_tokens = response_1.strip().split()[:1]\n",
        "\n",
        "    # If the two tokens are \"No,\", the query is informational\n",
        "    if \" \".join(first_two_tokens) == \"No,\":\n",
        "        response_2 = chain2.invoke(input_data)\n",
        "        return response_2 \n",
        "    \n",
        "    # Otherwise, the query is action\n",
        "    else:\n",
        "        input_data = {\"context\": context, \"query\": query, \"current_date\": date}\n",
        "        response_3 = chain3.invoke(input_data)\n",
        "\n",
        "        response_3 = extract_json_from_llm_response(response_3)\n",
        "        return response_3\n",
        "\n",
        "# Get the current date\n",
        "current_date = datetime.now().strftime(\"%Y-%m-%d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: How many Laser Cutter machines are there?\n",
            "\n",
            "Response: 2 Laser Cutter machines\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n",
            "\n",
            "Query: Show me the available KPIs for the Laser Cutter machines.\n",
            "\n",
            "Response:  The available KPIs for the Laser Cutter machines are WorkingTime, IdleTime, OfflineTime, TotalAvailableTime, and UtilizationRate.\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n",
            "\n",
            "Query: Is there a KPI for material cost?\n",
            "\n",
            "Response:  No, the provided context does not mention any Key Performance Indicator (KPI) specifically for material cost.\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n",
            "\n",
            "Query: Is there a KPI for that measures the percentage of time working?\n",
            "\n",
            "Response:  Yes, the KPI 'WorkingTime' measures the time actively working in seconds and it is a base KPI. However, if you are looking for a KPI that provides the percentage of time working, then 'UtilizationRate' would be the appropriate choice as it calculates the percentage of time actively working while available.\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Examples of informative queries\n",
        "queries_info = [\n",
        "    \"How many Laser Cutter machines are there?\",\n",
        "    \"Show me the available KPIs for the Laser Cutter machines.\",\n",
        "    \"Is there a KPI for material cost?\",\n",
        "    \"Is there a KPI for that measures the percentage of time working?\",\n",
        "]\n",
        "\n",
        "for query in queries_info:\n",
        "    # Retrieve relevant context using the retriever\n",
        "    context_docs = retriever.invoke(query)\n",
        "    context = \" \".join([doc.page_content for doc in context_docs])\n",
        "\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    # print(f\"\\nContext: {context}\")\n",
        "\n",
        "    response = steps(query, context, current_date)\n",
        "    \n",
        "    print(\"\\nResponse: {}\".format(response))\n",
        "    print(\"\\n\")\n",
        "    print(\"-\" * 12)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: What was the utilization rate for LaserCutter_1 the 2 of November?\n",
            "\n",
            "Response: {'KPI_name': 'UtilizationRate', 'machine_name': 'LaserCutter_1', 'start_range': '2024-11-02', 'end_range': 'null', 'aggregation': 'null', 'operation': 'null'}\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n",
            "\n",
            "Query: What is the utilization rate for LaserCutter_1 yesteday?\n",
            "\n",
            "Response: {'KPI_name': 'UtilizationRate', 'machine_name': 'LaserCutter_1', 'start_range': '2024-11-22', 'end_range': 'null', 'aggregation': 'null', 'operation': 'null'}\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n",
            "\n",
            "Query: What was the working time for LaserCutter_1 over the past week?\n",
            "\n",
            "Response: {'KPI_name': 'WorkingTime', 'machine_name': 'LaserCutter_1', 'start_range': '2024-11-16', 'end_range': '2024-11-22', 'aggregation': 'null', 'operation': 'null'}\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n",
            "\n",
            "Query: What is the value of the total avaiable time for Laser cutter 1 in the month of agust?\n",
            "\n",
            "Response: {'KPI_name': 'TotalAvailableTime', 'machine_name': 'LaserCutter_1', 'start_range': '2024-08-01', 'end_range': '2024-08-31', 'aggregation': 'null', 'operation': 'null'}\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n",
            "\n",
            "Query: What is the average of utilization rate for laser cutter 2 between september and october?\n",
            "\n",
            "Response: {'KPI_name': 'UtilizationRate', 'machine_name': 'LaserCutter_2', 'start_range': '2024-09-01', 'end_range': '2024-10-31', 'aggregation': None, 'operation': 'average'}\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n",
            "\n",
            "Query: Provide the monthly sum of time idle but available of laser cutter 2 from July to September.\n",
            "\n",
            "Response: {'KPI_name': 'IdleTime', 'machine_name': 'LaserCutter_2', 'start_range': '2024-07-01', 'end_range': '2024-09-30', 'aggregation': 'monthly', 'operation': 'sum'}\n",
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Examples of action queries\n",
        "queries_action = [\n",
        "    \"What was the utilization rate for LaserCutter_1 the 2 of November?\",\n",
        "    \"What is the utilization rate for LaserCutter_1 yesteday?\",\n",
        "    \"What was the working time for LaserCutter_1 over the past week?\",\n",
        "    \"What is the value of the total avaiable time for Laser cutter 1 in the month of agust?\",\n",
        "    \"What is the average of utilization rate for laser cutter 2 between september and october?\",\n",
        "    \"Provide the monthly sum of time idle but available of laser cutter 2 from July to September.\"\n",
        "]\n",
        "\n",
        "for query in queries_action:\n",
        "    # Retrieve relevant context using the retriever\n",
        "    context_docs = retriever.invoke(query)\n",
        "    context = \" \".join([doc.page_content for doc in context_docs])\n",
        "\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    # print(f\"\\nContext: {context}\")\n",
        "\n",
        "    response = steps(query, context, current_date)\n",
        "    \n",
        "    print(\"\\nResponse: {}\".format(response))\n",
        "    print(\"\\n\")\n",
        "    print(\"-\" * 12)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Elaboration steps of KPI engine output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the different types of action queries we have identified, there are two possible types of output:\n",
        "-\tSingle Value Response: If the query yields a single value, both the query and the calculated value are passed to the model and it generates the response directly.\n",
        "-\tList of Values Response: If the query yields a list of values, a table is used to present the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Different prompts for different types of outputs\n",
        "single_value_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Please answer the following question using the provided value and the given unit of measurement. \n",
        "    Your answer should be direct and concise, focusing specifically on addressing the question. \n",
        "    If the question asks for additional details, provide only the specific information requested. \n",
        "    Do not introduce information or explanations beyond what is directly asked for in the question. \n",
        "    Value: {value}. Unit of measurement: {unit}. Query: {query}. \n",
        "    Answer:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "table_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Create a brief and concise introductory statement that describes the table’s content based on the given query. Use just one statement. \n",
        "    \n",
        "    Example:\n",
        "    - Query: What was the working time for LaserCutter_1 over the past week?\n",
        "    - Output: Below is the working time for LaserCutter_1 over the past week:\n",
        "    Query: {query}.\n",
        "    Answer:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Different chains \n",
        "chain4 = (\n",
        "    {\n",
        "        'query': RunnablePassthrough(), \n",
        "        'value': RunnablePassthrough(),\n",
        "        'unit': RunnablePassthrough(),\n",
        "    }\n",
        "    | single_value_prompt \n",
        "    | model   \n",
        "    | StrOutputParser()  \n",
        ")\n",
        "\n",
        "chain5 = (\n",
        "    {\n",
        "        'query': RunnablePassthrough()\n",
        "    }\n",
        "    | table_prompt  \n",
        "    | model   \n",
        "    | StrOutputParser()  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def response_creation(query, kpi_response):\n",
        "    # Check the KPI engine output\n",
        "\n",
        "    if \"value\" in kpi_response:\n",
        "        # Single value\n",
        "        kpi_value = kpi_response[\"value\"]\n",
        "        unit = kpi_response[\"unit\"]\n",
        "\n",
        "        input_data = {\"value\": kpi_value, \"unit\": unit, \"query\": query}\n",
        "        response_4 = chain4.invoke(input_data)\n",
        "        return response_4\n",
        "\n",
        "    elif \"values\" in kpi_response:\n",
        "        # Multiple values\n",
        "        values = kpi_response[\"values\"]\n",
        "        unit = kpi_response[\"unit\"]\n",
        "        kpi_name = kpi_response[\"kpi_name\"]\n",
        "\n",
        "        operation = kpi_response[\"operation\"]\n",
        "\n",
        "        # Determine the column header based on the operation\n",
        "        if operation:\n",
        "            column_name = f\"{operation.capitalize()} Value\"\n",
        "        else:\n",
        "            column_name = \"Value\"\n",
        "        \n",
        "        aggregation = kpi_response.get(\"aggregation\")\n",
        "\n",
        "        # Determine the column headers based on the aggregation\n",
        "        if aggregation:\n",
        "            date_columns = \"| From         | To           |\"\n",
        "        else:\n",
        "            date_columns = \"| Date         |\"\n",
        "\n",
        "        # Constructing the Markdown table\n",
        "        table_header = f\"{date_columns} {column_name} |\\n\"\n",
        "        table_separator = \"|--------------\" * (2 if aggregation else 1) + \"|-------------------|\\n\"\n",
        "\n",
        "        table_rows = \"\"\n",
        "        if aggregation:\n",
        "            # Use start_date and end_date for each value entry\n",
        "            for entry in values:\n",
        "                table_rows += f\"| {entry['start_date']} | {entry['end_date']} | {entry['value']}{unit} |\\n\"\n",
        "        else:\n",
        "            # Use date and value fields for each row\n",
        "            for entry in values:\n",
        "                table_rows += f\"| {entry['date']} | {entry['value']} {unit} |\\n\"\n",
        "\n",
        "        # Combine header, separator, and rows to create the full markdown table\n",
        "        table_markdown = f\"{table_header}{table_separator}{table_rows}\"\n",
        "\n",
        "        #print(table_markdown)\n",
        "\n",
        "        # Let the model generate an introduction to the data\n",
        "        input_data = {\"query\": query}\n",
        "        response_5 = chain5.invoke(input_data)\n",
        "        complete_response = f\"{response_5}\\n\\n{table_markdown}\"\n",
        "\n",
        "        return complete_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example 1:\n",
            "Query: What is the average temperature recorded by Sensor_X during October?\n",
            " The average temperature recorded by Sensor_X during October was 25.3 degrees Celsius.\n",
            "\n",
            "Example 2:\n",
            "Query: Provide the weekly production rates for Factory_1 over the past month.\n",
            " Below is the weekly production rate for Factory_1 over the past month:\n",
            "\n",
            "This statement provides a clear and concise summary of the table's content based on the given query. It lets the user know that they will be receiving the weekly production rates for Factory_1 over the past month from the table.\n",
            "\n",
            "| From         | To           | Sum Value |\n",
            "|--------------|--------------|-------------------|\n",
            "| 2024-11-01 | 2024-11-07 | 1500units |\n",
            "| 2024-11-08 | 2024-11-14 | 1600units |\n",
            "| 2024-11-15 | 2024-11-21 | 1400units |\n",
            "\n",
            "\n",
            "Example 3:\n",
            "Query: Show the utilization rate for Machine_Z over the past week.\n",
            " Below is the utilization rate for Machine_Z over the past week:\n",
            "\n",
            "This statement provides a clear and concise introduction to the table's content, indicating that the data presented will show the utilization rate of Machine_Z over the past week.\n",
            "\n",
            "| Date         | Value |\n",
            "|--------------|-------------------|\n",
            "| 2024-11-02 | 72.4 % |\n",
            "| 2024-11-03 | 75.8 % |\n",
            "| 2024-11-04 | 78.1 % |\n",
            "| 2024-11-05 | 80.3 % |\n",
            "| 2024-11-06 | 74.5 % |\n",
            "| 2024-11-07 | 82.1 % |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "examples = [\n",
        "    # Example 1: Single Value Response\n",
        "    (\n",
        "        \"What is the average temperature recorded by Sensor_X during October?\",\n",
        "        {\n",
        "            \"machine_name\": \"Sensor_X\",\n",
        "            \"kpi_name\": \"AverageTemperature\",\n",
        "            \"value\": 25.3,\n",
        "            \"unit\": \"°C\"\n",
        "        }\n",
        "    ),\n",
        "    # Example 2: Multiple Values Response (Aggregated Data)\n",
        "    (\n",
        "        \"Provide the weekly production rates for Factory_1 over the past month.\",\n",
        "        {\n",
        "            \"machine_name\": \"Factory_1\",\n",
        "            \"kpi_name\": \"WeeklyProductionRate\",\n",
        "            \"operation\": \"sum\",\n",
        "            \"aggregation\": True,\n",
        "            \"values\": [\n",
        "                {\"start_date\": \"2024-11-01\", \"end_date\": \"2024-11-07\", \"value\": 1500},\n",
        "                {\"start_date\": \"2024-11-08\", \"end_date\": \"2024-11-14\", \"value\": 1600},\n",
        "                {\"start_date\": \"2024-11-15\", \"end_date\": \"2024-11-21\", \"value\": 1400}\n",
        "            ],\n",
        "            \"unit\": \"units\"\n",
        "        }\n",
        "    ),\n",
        "    # Example 3: Multiple Values Response (Daily Data)\n",
        "    (\n",
        "        \"Show the utilization rate for Machine_Z over the past week.\",\n",
        "        {\n",
        "            \"machine_name\": \"Machine_Z\",\n",
        "            \"kpi_name\": \"UtilizationRate\",\n",
        "            \"operation\": None,\n",
        "            \"aggregation\": None,\n",
        "            \"values\": [\n",
        "                {\"date\": \"2024-11-02\", \"value\": 72.4},\n",
        "                {\"date\": \"2024-11-03\", \"value\": 75.8},\n",
        "                {\"date\": \"2024-11-04\", \"value\": 78.1},\n",
        "                {\"date\": \"2024-11-05\", \"value\": 80.3},\n",
        "                {\"date\": \"2024-11-06\", \"value\": 74.5},\n",
        "                {\"date\": \"2024-11-07\", \"value\": 82.1}\n",
        "            ],\n",
        "            \"unit\": \"%\"\n",
        "        }\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "# Loop through each example case and generate the response\n",
        "for index, (query, kpi_response) in enumerate(examples):\n",
        "    print(f\"\\nExample {index + 1}:\")\n",
        "    try:\n",
        "        print(f\"Query: {query}\")\n",
        "        definitive_response = response_creation(query, kpi_response)\n",
        "        print(definitive_response)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "SA_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
