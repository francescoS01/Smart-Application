{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all libraries, create engine, Feast apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\utente\\anaconda3\\envs\\DM\\lib\\site-packages\\feast\\feature_view.py:48: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity '__dummy'.\n",
      "  DUMMY_ENTITY = Entity(\n"
     ]
    }
   ],
   "source": [
    "from feature_store_utils import *\n",
    "import pytz\n",
    "tz = pytz.timezone('Europe/Rome')\n",
    "\n",
    "engine = new_engine()\n",
    "#store = start_store(\"postgres_store/feature_repo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Postgres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1 Insert data to SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati inseriti con successo nella tabella 'historical_store'.\n",
      "Dati inseriti con successo nella tabella 'kpi_machine_agg_params'.\n"
     ]
    }
   ],
   "source": [
    "historical_data = {\n",
    "    \"timestamp\": [\n",
    "        datetime.now(tz),\n",
    "        datetime(2024, 11, 21, 8, 12, 10),\n",
    "        datetime(2024, 11, 17, 16, 40, 26),\n",
    "        datetime(2024, 11, 21, 8, 12, 10)\n",
    "    ],\n",
    "    \"machineid\": ['1','2','3','1'],\n",
    "    \"kpi\": ['x_acceleration','y_acceleration','z_acceleration','x_acceleration'],\n",
    "    \"aggregation_type\": ['sum','min','avg','min'],\n",
    "    \"value\": [1.0, 2.0, 3.0, 4.0],\n",
    "    \"imputation\": [False, False, True, False],\n",
    "    \"anomaly\": [False, False, True, False],\n",
    "    \"trend_drift\": [0.1, 0.2, 0.3, 0.4],\n",
    "    \"next_days_predictions\": [[75.5, 75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4, 77.5],\n",
    "                            [75.5, 75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4, 77.5],\n",
    "                            [75.5, 75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4, 77.5],\n",
    "                            [75.5, 75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4, 77.5]],\n",
    "    \"confidence_interval_lower\": [[75.4, 75.5, 75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4],\n",
    "                                  [75.4, 75.5, 75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4],\n",
    "                                  [75.4, 75.5, 75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4],\n",
    "                                  [75.4, 75.5, 75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4]],\n",
    "    \"confidence_interval_upper\": [[75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4, 77.5, 77.6],\n",
    "                                  [75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4, 77.5, 77.6],\n",
    "                                  [75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4, 77.5, 77.6],\n",
    "                                  [75.6, 75.7, 75.8, 75.9, 76.0, 76.1, 76.2, 76.3, 76.4, 76.5, 76.6, 76.7, 76.8, 76.9, 77.0, 77.1, 77.2, 77.3, 77.4, 77.5, 77.6]]\n",
    "    }\n",
    "historical_data_df = pd.DataFrame(historical_data)\n",
    "insert_data_to_sql(historical_data_df, \"historical_store\", engine)\n",
    "\n",
    "params_data = {\n",
    "    \"timestamp\": [datetime(2024, 11, 21, 8, 12, 10)],\n",
    "    \"machineid\": ['1'],\n",
    "    \"kpi\": ['x_acceleration'],\n",
    "    \"aggregation_type\": ['sum'],\n",
    "    \"min_threshold\": [0.0],\n",
    "    \"max_threshold\": [2.0],\n",
    "    \"selected_f\": [3]\n",
    "}\n",
    "params_data_df = pd.DataFrame(params_data)\n",
    "insert_data_to_sql(params_data_df, \"kpi_machine_agg_params\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.2 Delete data from SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE FROM historical_store WHERE machineid = '2' AND timestamp >= '2021-11-21 08:12:10' AND timestamp <= '2029-11-21 08:12:10'\n",
      "Dati eliminati con successo dalla tabella 'historical_store'.\n"
     ]
    }
   ],
   "source": [
    "conditions = {\n",
    "    \"machineid\": '2'\n",
    "}\n",
    "delete_data_from_sql(\"historical_store\", engine, conditions, start_time=datetime(2021, 11, 21, 8, 12, 10), end_time=datetime(2029, 11, 21, 8, 12, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.3 Get data from SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value  imputation  anomaly  trend_drift     next_days_predictions\n",
      "0    1.0        True     True            1  [75.5, 75.6, 75.7, 75.8]\n",
      "1    1.0       False     True            1  [75.5, 75.6, 75.7, 75.8]\n"
     ]
    }
   ],
   "source": [
    "table_name = \"historical_store\"\n",
    "attributes = ['value', 'imputation', 'anomaly', 'trend_drift', 'next_days_predictions']  # Mantieni la lista di attributi\n",
    "conditions = {\n",
    "    'machineid': ['444'],\n",
    "    'kpi': ['x_acceleration'],\n",
    "}\n",
    "\n",
    "# Definisci l'intervallo di tempo\n",
    "start_time = datetime(2023, 12, 21, 8, 12, 10)\n",
    "end_time = datetime(2026, 12, 21, 8, 12, 10)\n",
    "\n",
    "# Esegui la query\n",
    "result_df = get_data_from_sql(table_name, engine, attributes, conditions, start_time, end_time)\n",
    "\n",
    "# Stampa tutti i risultati\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Redis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1 Insert data to redis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati inseriti con successo in Redis.\n"
     ]
    }
   ],
   "source": [
    "# Crea un DataFrame con i dati da inserire\n",
    "new_data = {\n",
    "    \"timestamp\": [\n",
    "        datetime.now()\n",
    "    ],\n",
    "    \"machineid\": ['444'],\n",
    "    \"kpi\": ['x_acceleration'],\n",
    "    \"aggregation_type\": ['avg'],\n",
    "    \"value\": [1.0],\n",
    "    \"imputation\": [False],\n",
    "    \"anomaly\": [True],\n",
    "    \"trend_drift\": [1],\n",
    "    \"next_days_predictions\": [\n",
    "        [75.5, 75.6, 75.7, 75.8]\n",
    "    ],\n",
    "    \"confidence_interval_lower\": [\n",
    "        [75.4, 75.5, 75.6, 75.7]\n",
    "    ],\n",
    "    \"confidence_interval_upper\": [\n",
    "        [75.6, 75.7, 75.8, 75.9]\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(new_data)\n",
    "\n",
    "# Inserisci i dati in Redis\n",
    "insert_data_to_redis(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2 Get filtered online features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching data found.\n"
     ]
    }
   ],
   "source": [
    "# Definisci le condizioni di ricerca\n",
    "conditions = {\n",
    "    'machineid': ['444'],\n",
    "    'kpi': ['x_acceleration', 'y_acceleration'],\n",
    "    'aggregation_type': ['avg']\n",
    "}\n",
    "\n",
    "# Estrai i dati da Redis che soddisfano le condizioni\n",
    "data = get_data_from_redis_with_conditions(conditions)\n",
    "\n",
    "# Visualizza i risultati\n",
    "if data:\n",
    "    for record in data:\n",
    "        print(record)\n",
    "else:\n",
    "    print(\"No matching data found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = {\n",
    "    'machineid': ['444'],\n",
    "    'kpi': ['x_acceleration'],\n",
    "    'aggregation_type': ['avg'],\n",
    "    'timestamp': [datetime(2024, 11, 21, 8, 12, 10)]\n",
    "}\n",
    "\n",
    "\n",
    "delete_data_from_redis(conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Both: Redis and Postgres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1 Insert new data (Insert data in both)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un DataFrame con i dati da inserire\n",
    "new_data = {\n",
    "    \"timestamp\": [\n",
    "        datetime.now()\n",
    "    ],\n",
    "    \"machineid\": ['444'],\n",
    "    \"kpi\": ['x_acceleration'],\n",
    "    \"aggregation_type\": ['avg'],\n",
    "    \"value\": [1.0],\n",
    "    \"imputation\": [True],\n",
    "    \"anomaly\": [True],\n",
    "    \"trend_drift\": [1],\n",
    "    \"next_days_predictions\": [\n",
    "        [75.5, 75.6, 75.7, 75.8]\n",
    "    ],\n",
    "    \"confidence_interval_lower\": [\n",
    "        [75.4, 75.5, 75.6, 75.7]\n",
    "    ],\n",
    "    \"confidence_interval_upper\": [\n",
    "        [75.6, 75.7, 75.8, 75.9]\n",
    "    ]\n",
    "}\n",
    "\n",
    "new_data_df = pd.DataFrame(new_data)\n",
    "insert_new_data(new_data_df, \"historical_store\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **check if they are entered into both correctly:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2 Get data from SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"historical_store\"\n",
    "attributes = ['value', 'imputation', 'anomaly', 'trend_drift', 'next_days_predictions']\n",
    "attributes=None\n",
    "conditions = {\n",
    "    'machineid': ['444'],\n",
    "    'kpi': ['x_acceleration'],\n",
    "    }\n",
    "start_time = datetime(2023, 1, 21, 8, 12, 10)\n",
    "end_time = datetime(2024, 12, 21, 8, 12, 10)\n",
    "result_df = get_data_from_sql(table_name, engine, attributes, conditions, start_time, end_time)\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3 Get data from redis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci le condizioni di ricerca\n",
    "conditions = {\n",
    "    'machineid': ['444'],\n",
    "    'kpi': ['x_acceleration'],\n",
    "    'aggregation_type': ['avg']\n",
    "}\n",
    "\n",
    "# Estrai i dati da Redis che soddisfano le condizioni\n",
    "data = get_data_from_redis_with_conditions(conditions)\n",
    "\n",
    "# Visualizza i risultati\n",
    "if data:\n",
    "    for record in data:\n",
    "        print(record)\n",
    "else:\n",
    "    print(\"No matching data found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Test Update**\n",
    "In this update, a function executed periodically was implemented that analyzes the data stored in Redis (the online store) and checks whether there are records among them with a timestamp older than a certain time threshold. Records exceeding this threshold are deleted from Redis and transferred to a historical SQL database. \n",
    "Consequently, by setting, for example, a threshold of one day, only data from the last day will remain in Redis, while older records will have been stored in the historical database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this test example, a threshold of one minute is used (initialized in function redis_to_sql() in the file 'Storage/redis_to_sql.py'). This means that only data from the last minute will remain in Redis—an unrealistic scenario but useful for demonstrating how the process works.\n",
    "\n",
    "First, a piece of data is inserted into Redis. We then attempt to retrieve it from both Redis and the SQL database, confirming that the data is correctly stored in Redis but not yet present in SQL.\n",
    "\n",
    "Next, there is a 90-second sleep period. After this delay, we attempt to retrieve the same data again from both Redis and SQL. This time, we observe that the data is now present in SQL and no longer in Redis, confirming that the transfer has been successfully completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati inseriti con successo in Redis.\n",
      "\n",
      "\n",
      "Ricerca del dato inserito in redis\n",
      "il dato inserito è presente in redis: {'timestamp': Timestamp('2025-02-01 20:53:00.167591'), 'value': 1.0, 'imputation': True, 'anomaly': True, 'trend_drift': 1, 'next_days_predictions': [75.5, 75.6, 75.7, 75.8], 'confidence_interval_lower': [75.4, 75.5, 75.6, 75.7], 'confidence_interval_upper': [75.6, 75.7, 75.8, 75.9]}\n",
      "\n",
      "\n",
      "Ricerca del dato inserito in SQL\n",
      "Nessun dato presente con le condizioni: {'machineid': ['444'], 'kpi': ['x_acceleration']}\n",
      "\n",
      "\n",
      "---- sleep e trasferimento da online a storico ----\n",
      "\n",
      "\n",
      "\n",
      "Ricerca del dato inserito in redis\n",
      "il dato inserito non è presente in redis\n",
      "\n",
      "\n",
      "Ricerca del dato inserito in SQL\n",
      "Il dato inserito è presente in SQL:\n",
      "   value  imputation  anomaly  trend_drift     next_days_predictions\n",
      "0    1.0        True     True            1  [75.5, 75.6, 75.7, 75.8]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "new_data = {\n",
    "    \"timestamp\": [\n",
    "        datetime.now()\n",
    "    ],\n",
    "    \"machineid\": ['444'],\n",
    "    \"kpi\": ['x_acceleration'],\n",
    "    \"aggregation_type\": ['avg'],\n",
    "    \"value\": [1.0],\n",
    "    \"imputation\": [True],\n",
    "    \"anomaly\": [True],\n",
    "    \"trend_drift\": [1],\n",
    "    \"next_days_predictions\": [\n",
    "        [75.5, 75.6, 75.7, 75.8]\n",
    "    ],\n",
    "    \"confidence_interval_lower\": [\n",
    "        [75.4, 75.5, 75.6, 75.7]\n",
    "    ],\n",
    "    \"confidence_interval_upper\": [\n",
    "        [75.6, 75.7, 75.8, 75.9]\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# ---- insetimento di un nuovo dato in redis ----\n",
    "new_data_df = pd.DataFrame(new_data)\n",
    "insert_data_to_redis(new_data_df)\n",
    "\n",
    "\n",
    "# ---- ricerca del dato inserito in redis ----\n",
    "print(\"\\n\\nRicerca del dato inserito in redis\")\n",
    "conditions = {\n",
    "    'machineid': ['444'],\n",
    "    'kpi': ['x_acceleration'],\n",
    "    'aggregation_type': ['avg']\n",
    "}\n",
    "data = get_data_from_redis_with_conditions(conditions)\n",
    "if data:\n",
    "    for record in data:\n",
    "        print(f\"il dato inserito è presente in redis: {record}\")\n",
    "else:\n",
    "    print(\"No matching data found.\")\n",
    "\n",
    "\n",
    "# ---- ricerca del dato inserito in sql ----\n",
    "print(\"\\n\\nRicerca del dato inserito in SQL\")\n",
    "table_name = \"historical_store\"\n",
    "attributes = ['value', 'imputation', 'anomaly', 'trend_drift', 'next_days_predictions']  # Mantieni la lista di attributi\n",
    "conditions = {\n",
    "    'machineid': ['444'],\n",
    "    'kpi': ['x_acceleration'],\n",
    "}\n",
    "start_time = datetime(2023, 12, 21, 8, 12, 10)\n",
    "end_time = datetime(2026, 12, 21, 8, 12, 10)\n",
    "result_df = get_data_from_sql(table_name, engine, attributes, conditions, start_time, end_time)\n",
    "if not result_df.empty:\n",
    "    print(\"Il dato inserito è presente in SQL:\")\n",
    "    print(result_df)\n",
    "else:\n",
    "    print(\"Nessun dato presente con le condizioni:\", conditions)\n",
    "\n",
    "\n",
    "print(\"\\n\\n---- sleep e trasferimento da online a storico ----\\n\")\n",
    "time.sleep(90)\n",
    "\n",
    "# ---- ricerca del dato inserito in redis ----\n",
    "print(\"\\n\\nRicerca del dato inserito in redis\")\n",
    "conditions = {\n",
    "    'machineid': ['444'],\n",
    "    'kpi': ['x_acceleration'],\n",
    "    'aggregation_type': ['avg']\n",
    "}\n",
    "data = get_data_from_redis_with_conditions(conditions)\n",
    "if data:\n",
    "    for record in data:\n",
    "        print(f\"il dato inserito è presente in redis: {record}\")\n",
    "else:\n",
    "    print(\"il dato inserito non è presente in redis\")\n",
    "\n",
    "\n",
    "# ---- ricerca del dato inserito in sql ----\n",
    "print(\"\\n\\nRicerca del dato inserito in SQL\")\n",
    "table_name = \"historical_store\"\n",
    "attributes = ['value', 'imputation', 'anomaly', 'trend_drift', 'next_days_predictions']  # Mantieni la lista di attributi\n",
    "conditions = {\n",
    "    'machineid': ['444'],\n",
    "    'kpi': ['x_acceleration'],\n",
    "}\n",
    "start_time = datetime(2023, 12, 21, 8, 12, 10)\n",
    "end_time = datetime(2026, 12, 21, 8, 12, 10)\n",
    "result_df = get_data_from_sql(table_name, engine, attributes, conditions, start_time, end_time)\n",
    "if not result_df.empty:\n",
    "    print(\"Il dato inserito è presente in SQL:\")\n",
    "    print(result_df)\n",
    "else:\n",
    "    print(\"Nessun dato presente con le condizioni:\", conditions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
